{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import xgboost as xgb\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round2의 weather 예측값 전처리(Expert model의 input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_real = pd.read_csv(\"./weather_actual.csv\")\n",
    "weather_index = weather_real['time']\n",
    "\n",
    "weather = pd.read_csv(\"./weather_forecast.csv\")\n",
    "weather1 = weather[weather['round']==1].copy()\n",
    "weather2 = weather[weather['round']==2].copy()\n",
    "weather1_index = weather1.reset_index(drop=True)['time']\n",
    "weather2_index = weather2.reset_index(drop=True)['time']\n",
    "weather1_val = pd.read_csv(\"./weather_forecast_round1_val.csv\")\n",
    "weather2_val = pd.read_csv(\"./weather_forecast_round2_val.csv\")\n",
    "\n",
    "pred = pd.read_csv(\"./pred.csv\")\n",
    "pred1 = pred[pred['round']==1].copy()\n",
    "pred2 = pred[pred['round']==2].copy()\n",
    "pred1_index = pred1.reset_index(drop=True)['time']\n",
    "pred2_index = pred2.reset_index(drop=True)['time']\n",
    "pred1_val = pd.read_csv(\"./gen_forecast_round1_val.csv\")\n",
    "pred2_val = pd.read_csv(\"./gen_forecast_round2_val.csv\")\n",
    "\n",
    "gen = pd.read_csv(\"./gens.csv\")\n",
    "gen_val = pd.read_csv(\"./gens_val.csv\")\n",
    "gen_index = gen['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(weather2_index.tolist())\n",
    "B = np.array(pred2_index.tolist())\n",
    "C = np.array(gen_index.tolist())\n",
    "A1 = np.array(weather1_index.tolist())\n",
    "B1 = np.array(pred1_index.tolist())\n",
    "total_index = np.intersect1d(np.intersect1d(A,B),C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(np.setdiff1d(A,total_index)):\n",
    "    weather2.drop([weather2[weather2['time']==i].index.item()],inplace=True)\n",
    "\n",
    "for i in list(np.setdiff1d(B,total_index)):\n",
    "    pred2.drop(pred2[pred2['time']==i].transpose().columns,inplace=True)\n",
    "\n",
    "for i in list(np.setdiff1d(A1,total_index)):\n",
    "    weather1.drop([weather1[weather1['time']==i].index.item()],inplace=True)\n",
    "\n",
    "for i in list(np.setdiff1d(B1,total_index)):\n",
    "    pred1.drop(pred1[pred1['time']==i].transpose().columns,inplace=True)\n",
    "\n",
    "for i in list(np.setdiff1d(C,total_index)):\n",
    "    gen.drop([gen[gen['time']==i].index.item()],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_weather & pred_weather 오차\n",
    "weather1 = weather1.drop(['round','time'],axis=1)\n",
    "weather2 = weather2.drop(['round','time'],axis=1)\n",
    "weather1_val = weather1_val.drop(['round','time'],axis=1)\n",
    "weather2_val = weather2_val.drop(['round','time'],axis=1)\n",
    "\n",
    "ss1 = MinMaxScaler()\n",
    "ss2 = MinMaxScaler()\n",
    "\n",
    "ss_weather1 = pd.DataFrame(ss1.fit_transform(weather1))\n",
    "ss_weather2 = pd.DataFrame(ss2.fit_transform(weather2))\n",
    "ss_weather1_val = pd.DataFrame(ss1.transform(weather1_val))\n",
    "ss_weather2_val = pd.DataFrame(ss2.transform(weather2_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble_model1(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Ensemble_model1, self).__init__()\n",
    "        self.fe = nn.Linear(18, 128)\n",
    "        self.hidden1 = nn.Linear(128,128)\n",
    "        self.hidden2 = nn.Linear(128,128)\n",
    "        self.hidden3 = nn.Linear(128,128)\n",
    "        self.hidden4 = nn.Linear(128,128)\n",
    "        self.latent = nn.Linear(128, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, x1):\n",
    "        batch_size = len(x)\n",
    "        x = self.fe(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden4(x)\n",
    "        x = self.relu(x)\n",
    "        f = self.latent(x)\n",
    "        x = torch.sum(f*x1, 1).reshape(batch_size, -1)\n",
    "        x = self.relu(x)\n",
    "        return (x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble_model2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Ensemble_model2, self).__init__()\n",
    "        self.fe = nn.Linear(18, 64)\n",
    "        self.hidden1 = nn.Linear(64,64)\n",
    "        self.hidden2 = nn.Linear(64,64)\n",
    "        self.hidden3 = nn.Linear(64,64)\n",
    "        self.hidden4 = nn.Linear(64,64)\n",
    "        self.hidden5 = nn.Linear(64,64)\n",
    "        self.latent = nn.Linear(64, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, x1):\n",
    "        batch_size = len(x)\n",
    "        x = self.fe(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden5(x)\n",
    "        x = self.relu(x)\n",
    "        f = self.latent(x)\n",
    "        x = torch.sum(f*x1, 1).reshape(batch_size, -1)\n",
    "        x = self.relu(x)\n",
    "        return (x, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "### date : 입찰 일자+1 or 예측 대상 일자를 입력하면 됨\n",
    "#### 11월 12일 09:05(10시 입찰)에 입찰을 진행할 경우, 2023-11-13임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10시 입찰 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### 반드시 date 수정할 것 #######################\n",
    "date = \"2023-11-13\"\n",
    "###################### 반드시 date 수정할 것 #######################\n",
    "\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "_API_URL = \"https://research-api.solarkim.com\"\n",
    "_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJNZHNVVlNnbmhZb3h2NnllNWFoNGRaIiwiaWF0IjoxNjk4MTMzOTY2LCJleHAiOjE3MDAyMzMyMDAsInR5cGUiOiJhcGlfa2V5In0.bfOVN_dSXvvfJS2eeoqxcsL_pfgfv4DPqoWgm192CvA\"\n",
    "_AUTH_PARAM = {\"headers\": {\"Authorization\": f\"Bearer {_API_KEY}\"}}\n",
    "\n",
    "\n",
    "def _get(url: str):\n",
    "    response = requests.get(url, **_AUTH_PARAM)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def _post(url: str, data):\n",
    "    response = requests.post(url, data=json.dumps(data), **_AUTH_PARAM)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def _post_bids():\n",
    "    amounts = np.array(pd.read_csv(f\"./{date}_round1.csv\")).flatten().tolist()\n",
    "    success = _post(f\"{_API_URL}/cmpt-2023/bids\", amounts)\n",
    "    print('here',success)\n",
    "\n",
    "def _get_weathers_forecasts():\n",
    "    bid_round_10 = 1\n",
    "    bid_round_17 = 2\n",
    "    weather_fcst_10 = _get(\n",
    "        f\"{_API_URL}/cmpt-2023/weathers-forecasts/{date}/{bid_round_10}\"\n",
    "    )\n",
    "    weather_fcst_17 = _get(\n",
    "        f\"{_API_URL}/cmpt-2023/weathers-forecasts/{date}/{bid_round_17}\"\n",
    "    )\n",
    "    pd.DataFrame(weather_fcst_10).to_csv(f\"./weather_fcst_10_{date}.csv\",index=False)\n",
    "    pd.DataFrame(weather_fcst_17).to_csv(f\"./weather_fcst_17_{date}.csv\",index=False)\n",
    "\n",
    "\n",
    "def _get_gen_forecasts():\n",
    "    bid_round_10 = 1\n",
    "    bid_round_17 = 2\n",
    "    gen_fcst_10 = _get(f\"{_API_URL}/cmpt-2023/gen-forecasts/{date}/{bid_round_10}\")\n",
    "    gen_fcst_17 = _get(f\"{_API_URL}/cmpt-2023/gen-forecasts/{date}/{bid_round_17}\")\n",
    "    pd.DataFrame(gen_fcst_10).to_csv(f\"./gen_fcst_10_{date}.csv\",index=False)\n",
    "    pd.DataFrame(gen_fcst_17).to_csv(f\"./gen_fcst_17_{date}.csv\",index=False)\n",
    "\n",
    "_get_weathers_forecasts()\n",
    "_get_gen_forecasts()\n",
    "\n",
    "\n",
    "best_model1 = torch.load(f\"best_model_round1_{date}.pt\")\n",
    "test_weather = pd.read_csv(f\"weather_fcst_10_{date}.csv\") \n",
    "test_weather = test_weather.drop(['time'],axis=1)\n",
    "test_weather = test_weather\n",
    "ss_test_weather = pd.DataFrame(ss1.transform(test_weather), columns=test_weather.columns)\n",
    "\n",
    "\n",
    "test_pred = pd.read_csv(f\"gen_fcst_10_{date}.csv\")\n",
    "gen_test_pred = test_pred.drop(['time'],axis=1)\n",
    "\n",
    "\n",
    "ss_test_weather_dataset = torch.tensor(np.array(ss_test_weather)).type(torch.float32)\n",
    "gen_test_pred_dataset = torch.tensor(np.array(gen_test_pred)).type(torch.float32)\n",
    "\n",
    "total_test_dataset = torch.cat([ss_test_weather_dataset, gen_test_pred_dataset], dim=1)\n",
    "\n",
    "best_model1.eval()\n",
    "pred_y1 = best_model1(total_test_dataset, gen_test_pred_dataset)[0]\n",
    "\n",
    "pd.DataFrame(np.array(pred_y1.tolist())).to_csv(f\"{date}_round1.csv\",index=False)\n",
    "\n",
    "print(pred_y1)\n",
    "\n",
    "_post_bids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17시 입찰코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### 반드시 date 수정할 것 #######################\n",
    "date = \"2023-11-13\"\n",
    "###################### 반드시 date 수정할 것 #######################\n",
    "\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "_API_URL = \"https://research-api.solarkim.com\"\n",
    "_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJNZHNVVlNnbmhZb3h2NnllNWFoNGRaIiwiaWF0IjoxNjk4MTMzOTY2LCJleHAiOjE3MDAyMzMyMDAsInR5cGUiOiJhcGlfa2V5In0.bfOVN_dSXvvfJS2eeoqxcsL_pfgfv4DPqoWgm192CvA\"\n",
    "_AUTH_PARAM = {\"headers\": {\"Authorization\": f\"Bearer {_API_KEY}\"}}\n",
    "\n",
    "\n",
    "def _get(url: str):\n",
    "    response = requests.get(url, **_AUTH_PARAM)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def _post(url: str, data):\n",
    "    response = requests.post(url, data=json.dumps(data), **_AUTH_PARAM)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def _post_bids():\n",
    "    amounts = np.array(pd.read_csv(f\"./{date}_round2.csv\")).flatten().tolist()\n",
    "    success = _post(f\"{_API_URL}/cmpt-2023/bids\", amounts)\n",
    "    print('here',success)\n",
    "\n",
    "def _get_weathers_forecasts():\n",
    "    bid_round_10 = 1\n",
    "    bid_round_17 = 2\n",
    "    weather_fcst_10 = _get(\n",
    "        f\"{_API_URL}/cmpt-2023/weathers-forecasts/{date}/{bid_round_10}\"\n",
    "    )\n",
    "    weather_fcst_17 = _get(\n",
    "        f\"{_API_URL}/cmpt-2023/weathers-forecasts/{date}/{bid_round_17}\"\n",
    "    )\n",
    "    pd.DataFrame(weather_fcst_10).to_csv(f\"./weather_fcst_10_{date}.csv\",index=False)\n",
    "    pd.DataFrame(weather_fcst_17).to_csv(f\"./weather_fcst_17_{date}.csv\",index=False)\n",
    "\n",
    "\n",
    "def _get_gen_forecasts():\n",
    "    bid_round_10 = 1\n",
    "    bid_round_17 = 2\n",
    "    gen_fcst_10 = _get(f\"{_API_URL}/cmpt-2023/gen-forecasts/{date}/{bid_round_10}\")\n",
    "    gen_fcst_17 = _get(f\"{_API_URL}/cmpt-2023/gen-forecasts/{date}/{bid_round_17}\")\n",
    "    pd.DataFrame(gen_fcst_10).to_csv(f\"./gen_fcst_10_{date}.csv\",index=False)\n",
    "    pd.DataFrame(gen_fcst_17).to_csv(f\"./gen_fcst_17_{date}.csv\",index=False)\n",
    "\n",
    "_get_weathers_forecasts()\n",
    "_get_gen_forecasts()\n",
    "\n",
    "\n",
    "best_model2 = torch.load(f\"best_model_round2_{date}.pt\")\n",
    "test_weather = pd.read_csv(f\"weather_fcst_17_{date}.csv\") \n",
    "test_weather = test_weather.drop(['time'],axis=1)\n",
    "test_weather = test_weather\n",
    "ss_test_weather = pd.DataFrame(ss2.transform(test_weather), columns=test_weather.columns)\n",
    "\n",
    "\n",
    "test_pred = pd.read_csv(f\"gen_fcst_17_{date}.csv\")\n",
    "gen_test_pred = test_pred.drop(['time'],axis=1)\n",
    "\n",
    "\n",
    "ss_test_weather_dataset17 = torch.tensor(np.array(ss_test_weather)).type(torch.float32)\n",
    "gen_test_pred_dataset17 = torch.tensor(np.array(gen_test_pred)).type(torch.float32)\n",
    "\n",
    "total_test_dataset17 = torch.cat([ss_test_weather_dataset17, gen_test_pred_dataset17], dim=1)\n",
    "\n",
    "best_model2.eval()\n",
    "pred_y2 = best_model2(total_test_dataset17, gen_test_pred_dataset17)[0]\n",
    "\n",
    "pd.DataFrame(np.array(pred_y2.tolist())).to_csv(f\"{date}_round2.csv\",index=False)\n",
    "\n",
    "print(pred_y2)\n",
    "\n",
    "_post_bids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
